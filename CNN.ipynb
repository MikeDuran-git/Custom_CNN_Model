{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP4nfjF0HtbZ"
   },
   "source": [
    "On this project i will build a CNN, that can make a difference between a Cat and a Dog. This is a project is made to teach me some methods of pooling and flattening that the CNN methods use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLgl4hdczqVx"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ajUn1yRfzm7N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D # first step of convolution to build the feature mapping\n",
    "from keras.layers import MaxPooling2D # to maxpool.\n",
    "from keras.layers import Flatten # step3 to flatten our matrix.\n",
    "from keras.layers import Dense # to add fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oSSqVJLI-zt"
   },
   "source": [
    "# CNN BUILD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbMSYy2aJRbw"
   },
   "source": [
    "## Initalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyFetWyGJVnV"
   },
   "source": [
    "It's just like a simple ANN to initalize, we build de classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "08U6bsr3IJ-_"
   },
   "outputs": [],
   "source": [
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxW4cyPBNOVC"
   },
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlgpwzuNKCY3"
   },
   "source": [
    "after that we build the convolution layer. This is the layer where we build our feature maps, by translating our input img , into multiple matrixs.\n",
    "By using Convolution2D rather than Dense, to build our feature maps.\n",
    "- filter: the number of features we want. (32 is a standard on the first layer) if we make another convolutional layer we would double the filter value.\n",
    "- kernel_size: the matrix dimension of the feature detector, in our case we choose a 3x3 matrix. so a simple 3 value.\n",
    "- stride: the amount of pixel we move the feature detector.\n",
    "\n",
    "- input_shape: to specify the shape of our imgs, (width,height,3) if RGB and (width,height,1) if B&W. We will adapt our imgs to the specified width and height. In our case (64,64,3).\n",
    "- activation: the activation function we use \"relu\" because handling imgs is non linear, which makes relu a better option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KvyDTdBBJ280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MIKED\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(filters=32,kernel_size=3,strides=1,input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXkSlPUwNSB0"
   },
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMfGk0NWNvvD"
   },
   "source": [
    "In this step we reduce every feature map, into a smaller matrix, to make it easier to process. Creating the so called Pooling Layer. if we don't do it we will have WAY TO MUCH features.\n",
    "- pool_size: the dimension of the 'feature detector' in our case 2x2 . the strides will have the default value of 2 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9m5ztUaDM8kG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MIKED\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (added a second convolutional layer,to make better prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this case we don't need input_shape, because we already adapted our imgs the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(filters=32,kernel_size=3,strides=1,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we add a MAXPOOL for this case too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdKtyXSEPDqS"
   },
   "source": [
    "## Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aEBMP-qPGnT"
   },
   "source": [
    "We take all our pooled feature maps and align them to make the Entry layer for our ANN. Since now the structures of the img are represented as a high number, we can identify them as features for our entry layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Hpk91B9ROVn-"
   },
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_kHcjvcPnqy"
   },
   "source": [
    "Now we just need to build a simple ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbYSHOvVPsyE"
   },
   "source": [
    "## ANN build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jfq4h4nP0WO"
   },
   "source": [
    "We create a hidden layer. I choose the units=128 because we need high enough value for the amount of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VyMAflVePiSV"
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=128,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLXzPVXuQv9M"
   },
   "source": [
    "We build now the exit layer. Since this project is a classification of 2 possible outcomes, it would be wise to use the sigmoid activation function. (if we had multiple outcomes we could use the softmax function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QMmyUk18QpMw"
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyYSwtpIRBdD"
   },
   "source": [
    "now we compile the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GMpuIlKmQvJG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MIKED\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRyfjjm1Rl8E"
   },
   "source": [
    "# FIT the CNN to our imgs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjO4GgzMRsSJ"
   },
   "source": [
    "we need to fit the cnn to our imgs. We will use a technique that is called img augmentation, it prepares our imgs to reduce the risk of OVERFITTING to nothingness. Because to train a model, wee need a lot of imgs, this technique creates new imgs based on our current imgs.(for example just turn a img upside down.) The function is called : Flow_from_directory() we copy the functions from the keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "l2ffuRNtW67F"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTNCltcCXoc3"
   },
   "source": [
    "the steps per epoch is the value of the imgs divided by the bach size : wich makes in our case 8000 / 32 = 250, so we give it 250. for validation step we have 2000 imgs divided by 32 == 63."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7QNOf8BRiOQ",
    "outputId": "e6e08c20-4dc9-4f7c-8d44-f82e197bcd24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # change the scale value of every  (just like the standardization)\n",
    "        shear_range=0.2,# to make transvection = change the angle of which you see the img\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True) # to turn the img horizontaly.\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #we change everything on the same scale.\n",
    "\n",
    "# creates the new imgs.\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UT5TCYzE4pt5"
   },
   "source": [
    "for unknown reasons in google colab we find only 3270 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4A3MN5lzK4A",
    "outputId": "1ee7b328-3b8a-489b-ed17-5dc91015a7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for unknown reasons in google colab we find 0 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5jBfO49sYTwe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MIKED\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.6690 - accuracy: 0.5971 - val_loss: 0.6366 - val_accuracy: 0.6125\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 24s 95ms/step - loss: 0.6209 - accuracy: 0.6624 - val_loss: 0.4129 - val_accuracy: 0.6915\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.5774 - accuracy: 0.7009 - val_loss: 0.3902 - val_accuracy: 0.6980\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.5446 - accuracy: 0.7226 - val_loss: 0.6473 - val_accuracy: 0.7235\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.5085 - accuracy: 0.7487 - val_loss: 0.5678 - val_accuracy: 0.7325\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.4869 - accuracy: 0.7635 - val_loss: 0.9314 - val_accuracy: 0.7675\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.4778 - accuracy: 0.7717 - val_loss: 0.3704 - val_accuracy: 0.7780\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4554 - accuracy: 0.7821 - val_loss: 0.3174 - val_accuracy: 0.7775\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.4428 - accuracy: 0.7914 - val_loss: 0.3484 - val_accuracy: 0.7905\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.4304 - accuracy: 0.8005 - val_loss: 0.3898 - val_accuracy: 0.7850\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4150 - accuracy: 0.8075 - val_loss: 0.3122 - val_accuracy: 0.7715\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4045 - accuracy: 0.8123 - val_loss: 0.4200 - val_accuracy: 0.7825\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.3956 - accuracy: 0.8210 - val_loss: 0.4151 - val_accuracy: 0.8050\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.3899 - accuracy: 0.8196 - val_loss: 0.4512 - val_accuracy: 0.8030\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 32s 126ms/step - loss: 0.3693 - accuracy: 0.8313 - val_loss: 0.3512 - val_accuracy: 0.8060\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.3533 - accuracy: 0.8409 - val_loss: 0.4682 - val_accuracy: 0.8080\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.3478 - accuracy: 0.8468 - val_loss: 0.4975 - val_accuracy: 0.8100\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.3401 - accuracy: 0.8485 - val_loss: 0.2222 - val_accuracy: 0.8105\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.3374 - accuracy: 0.8464 - val_loss: 0.3083 - val_accuracy: 0.7795\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.3150 - accuracy: 0.8616 - val_loss: 0.8358 - val_accuracy: 0.8065\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.3060 - accuracy: 0.8679 - val_loss: 0.3447 - val_accuracy: 0.7980\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.2865 - accuracy: 0.8767 - val_loss: 0.3797 - val_accuracy: 0.8020\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.2813 - accuracy: 0.8795 - val_loss: 1.1037 - val_accuracy: 0.8095\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.2635 - accuracy: 0.8894 - val_loss: 0.3382 - val_accuracy: 0.8075\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.2553 - accuracy: 0.8931 - val_loss: 0.7072 - val_accuracy: 0.8065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2ceb3108c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trains the model and measures his performance.\n",
    "classifier.fit(\n",
    "        training_set,\n",
    "        steps_per_epoch=250, #everytime we reajust the epochs\n",
    "        epochs=25,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6amIiSbs4lvM"
   },
   "source": [
    "this takes a long time....(first run without the second convolutional layer) 0.76 is not very high in my point of view, so i will add some convolutional layers... (ps at first i used only one convolutional layer, now i use 2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ru81BxzrxSqv"
   },
   "source": [
    "# Test on a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-58cbf07999f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset/single_prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "classifier.predict(\"dataset/single_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
